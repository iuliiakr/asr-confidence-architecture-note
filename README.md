# Multilingual ASR confidence is not a safe decision signal

## Overview

This repository documents an integration-level risk in multilingual speech pipelines:
<b>ASR confidence scores are not numerically comparable across languages and models when used as control signals.</b>

In production systems, confidence is commonly used to gate automation, trigger human review, or drive corrective feedback. In multilingual settings, this assumption leads to non-deterministic behavior.


## Architectural Context

This issue emerges in multiple common architectures, including:

1. Pronunciation Feedback Loops (Interactive Systems)
- ASR confidence determines whether learner pronunciation is corrected
- Miscalibrated confidence leads to false corrections or missed errors
- Effects are immediate and user-visible

2. TTS Corpus Creation Pipelines (Data Systems)
- ASR confidence gates automatic acceptance vs. human review
- Language-dependent confidence skew inflates validation costs
- Bias introduced at ingestion propagates into training data

Although the downstream systems differ, the architectural risk is the same: confidence is used as a decision signal without normalization across languages.


## Observed Divergence

A small evaluation across English, Hindi, and Ukrainian, using Google STT and Whisper, demonstrates that:
- Confidence distributions differ significantly by language for equivalent utterances
- Incorrect transcriptions may receive higher confidence than correct ones in other languages
- Model-specific confidence proxies are not aligned

As a result, identical numeric thresholds encode different reliability levels depending on language and model.

&nbsp;

## System-Level Impact

Using raw ASR confidence as a control signal introduces:
- inconsistent automation gating across languages,
- false corrective feedback in tutoring systems,
- unstable human review rates in data pipelines,
- unpredictable cost and UX behavior in global deployments.

The failure mode is architectural, not model-specific.

&nbsp;

## Architectural Implication

Raw confidence values encode provider- and language-specific semantics and cannot be consumed directly as decision signals without introducing non-deterministic system behavior.

Multilingual pipelines therefore require an explicit normalization boundary that translates model-specific confidence into task-level reliability guarantees.

&nbsp;

## Appendix: Sample Transcriptions and Confidence Outputs

This pilot is intentionally small and illustrative. It is not intended to measure model accuracy or compare providers.
Its sole purpose is to demonstrate an integration-level behavior observed when ASR confidence scores are used as control signals in multilingual pipelines.

### Setup

<b>Languages:</b> English (en), Hindi (hi), Ukrainian (uk)

<b>Utterances:</b> Short, semantically simple commands (3‚Äì6 words)

<b>Speaker:</b> single speaker; consistent recording conditions

<b>ASR Systems</b>:
- Google Speech-to-Text
- OpenAI Whisper

<b>Confidence Signals:</b>
- Google STT: provider-reported confidence score
- Whisper: average log probability per segment (used as a confidence proxy)

<b>Labels:</b> human-judged transcription correctness (binary)

&nbsp;

## Sample Outputs (Illustrative Only)


### Google STT

In the samples below, several Hindi transcriptions are assigned high confidence despite semantic or grammatical errors, illustrating that confidence values are not directly comparable across languages.

| Language | File | Human Reference | Model Output (Raw) | Confidence | Human Judgment |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **üá∫üá∏ English** | en-1.wav | I will arrive tomorrow morning. | I will arrive tomorrow morning. | 0.98 | ‚úÖ Correct |
| | en-2.wav | Please send me the file. | Please send me the file. | 0.98 | ‚úÖ Correct |
| | en-3.wav | Call me in the evening. | Call me in the evening. | 0.90 | ‚úÖ Correct |
| **üáÆüá≥ Hindi** | hi-1.wav | ‡§Æ‡•à‡§Ç ‡§ï‡§≤ ‡§∏‡•Å‡§¨‡§π ‡§™‡§π‡•Å‡§Å‡§ö‡•Ç‡§Å‡§ó‡•Ä‡•§ | ‡§Æ‡•à‡§Ç ‡§ï‡§≤ ‡§∏‡•Å‡§¨‡§π ‡§™‡§π‡•Å‡§Ç‡§ö‡•á‡§Ç‡§ó‡•á‡•§ | 0.90 | ‚ùå Agreement Error |
| | hi-2.wav | ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á ‡§´‡§º‡§æ‡§á‡§≤ ‡§≠‡•á‡§ú ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§ | ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á 5 ‡§≠‡•á‡§ú ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§ | 0.89 | ‚ùå Hallucination |
| | hi-3.wav | ‡§Æ‡•Å‡§ù‡•á ‡§∂‡§æ‡§Æ ‡§ï‡•ã ‡§´‡•ã‡§® ‡§ï‡§∞‡•ã‡•§ | ‡§Æ‡•Å‡§ù‡•á ‡§∂‡§æ‡§Æ ‡§ï‡•ã ‡§´‡•ã‡§® ‡§ï‡§∞‡•ã! | 0.96 | ‚úÖ Correct |
| **üá∫üá¶ Ukrainian** | uk-1.wav | –Ø –ø—Ä–∏—ó–¥—É –∑–∞–≤—Ç—Ä–∞ –≤—Ä–∞–Ω—Ü—ñ. | –Ø –ø—Ä–∏—ó–¥—É –∑–∞–≤—Ç—Ä–∞ –≤—Ä–∞–Ω—Ü—ñ. | 0.92 | ‚úÖ Correct | 
| | uk-2.wav | –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª–∏ –º–µ–Ω—ñ —Ñ–∞–π–ª. | –±—É–¥—å –ª–∞—Å–∫–∞ –ù–∞–¥—ñ—à–ª–∏ –º–µ–Ω—ñ —Ñ–∞–π–ª | 0.71 | ‚ö†Ô∏è Formatting Mismatch |
| | uk-3.wav | –ó–∞—Ç–µ–ª–µ—Ñ–æ–Ω—É–π –º–µ–Ω—ñ –≤–≤–µ—á–µ—Ä—ñ. | –∑–∞—Ç–µ–ª–µ—Ñ–æ–Ω—É–π –º–µ–Ω—ñ –≤–≤–µ—á–µ—Ä—ñ | 0.83 | ‚ö†Ô∏è Formatting Mismatch |

&nbsp;


### OpenAI's Whisper (large-v3)

Whisper does not expose an explicit confidence score. The avg_logprob shown below is Whisper‚Äôs average token log-probability for the decoded output and is commonly used as a proxy for internal model confidence. The examples illustrate that similar or higher log-probability values may correspond to both correct and incorrect transcriptions, depending on language and linguistic features.

| Language | File | Human Reference | Model Output (Raw) | avg_logprob | Human Judgment |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **üá∫üá∏ English** | en-1.wav | I will arrive tomorrow morning. | I will arrive tomorrow morning. | -0.18 | ‚úÖ Correct |
| | en-2.wav | Please send me the file. | Please send me the file. | -0.35 | ‚úÖ Correct |
| | en-3.wav | Call me in the evening. | Call me in the evening. | -0.49 | ‚úÖ Correct |
| **üáÆüá≥ Hindi** | hi-1.wav | ‡§Æ‡•à‡§Ç ‡§ï‡§≤ ‡§∏‡•Å‡§¨‡§π ‡§™‡§π‡•Å‡§Å‡§ö‡•Ç‡§Å‡§ó‡•Ä‡•§ | ‡§Æ‡•á‡§Ç ‡§ï‡§≤ ‡§∏‡•Å‡§¨‡•á ‡§™‡§ñ‡•Å‡§ö‡•Å‡§Ç‡§ó‡•Ä | -0.22 | ‚ùå 1 phonetic error |
| | hi-2.wav | ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á ‡§´‡§º‡§æ‡§á‡§≤ ‡§≠‡•á‡§ú ‡§¶‡•Ä‡§ú‡§ø‡§è‡•§ | ‡§ï‡•É‡§™‡§Ø‡§æ ‡§Æ‡•Å‡§ù‡•á ‡§´‡§æ‡§á‡§≤ ‡§≠‡•á‡§ú ‡§¶‡•Ä‡§ö‡§ø‡§Ø‡•á  | -0.15 | ‚ùå 1 phonetic error |
| | hi-3.wav | ‡§Æ‡•Å‡§ù‡•á ‡§∂‡§æ‡§Æ ‡§ï‡•ã ‡§´‡•ã‡§® ‡§ï‡§∞‡•ã‡•§ | ‡§Æ‡•Å‡§ù‡•á ‡§∂‡§æ‡§Æ ‡§ï‡•ã ‡§´‡•ã‡§® ‡§ï‡§∞‡•ã | -0.11 | ‚úÖ Correct |
| **üá∫üá¶ Ukrainian** | uk-1.wav | –Ø –ø—Ä–∏—ó–¥—É –∑–∞–≤—Ç—Ä–∞ –≤—Ä–∞–Ω—Ü—ñ. | –Ø –ø—Ä–∏—ó–¥—É –∑–∞–≤—Ç—Ä–∞ –≤—Ä–∞–Ω—Ü—ñ. | -0.15 | ‚úÖ Correct |
| | uk-2.wav | –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞–¥—ñ—à–ª–∏ –º–µ–Ω—ñ —Ñ–∞–π–ª. | –ë—É–¥—å –ª–∞—Å–∫–∞, –Ω–∞ –¥–µ—à–ª–∏–π –º–∞–Ω—ñ—Ñ–∞–π–ª. | -0.17 | ‚ùå Hallucination |
| | uk-3.wav | –ó–∞—Ç–µ–ª–µ—Ñ–æ–Ω—É–π –º–µ–Ω—ñ –≤–≤–µ—á–µ—Ä—ñ. | –ó–∞—Ç–µ–ª–µ—Ñ–æ–Ω—É–π –º–µ–Ω—ñ –≤–≤–µ—á–µ—Ä—ñ. | -0.11 | ‚úÖ Correct |


Human Judgment - these correctness labels reflect comparison between the raw model output and the human reference transcript:
- ‚úÖ Correct: Semantically and grammatically equivalent
- ‚ö†Ô∏è Formatting Mismatch: Punctuation, casing, or spacing differences without semantic impact
- ‚ùå Agreement Error: Grammatical error affecting correctness
- ‚ùå Hallucination: Lexical insertion, substitution, or meaning change
&nbsp;
